{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC65Q8UN35hC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "#from keras.layers import Dense, Embedding, LSTM, SimpleRNN, SpatialDropout1D\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional, Conv1D, GlobalMaxPool1D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6Zy7bH-hkp3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "qRtuB80o38mC",
        "outputId": "ef51eded-0e74-49b5-fd83-2dbfc9c01f95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             content  sentiment_labels\n",
              "0  feature search hotspot location able function ...              -1.0\n",
              "1                                               good               2.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9a63609-213f-4dc8-9deb-777f18882fd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>sentiment_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>feature search hotspot location able function ...</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>good</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9a63609-213f-4dc8-9deb-777f18882fd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9a63609-213f-4dc8-9deb-777f18882fd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9a63609-213f-4dc8-9deb-777f18882fd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/FinalDatasetmerged (1).csv\")\n",
        "data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEpx9V5-38uC",
        "outputId": "ed9c7c9c-58f2-4059-e980-d09e660becc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32183, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data=data.dropna()\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOm5NJxr38wv",
        "outputId": "8ce0aa35-2e43-4e2c-d3ec-48100949ac37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras.utils\n",
            "  Downloading keras-utils-1.0.13.tar.gz (2.4 kB)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras.utils) (2.8.0)\n",
            "Building wheels for collected packages: keras.utils\n",
            "  Building wheel for keras.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras.utils: filename=keras_utils-1.0.13-py3-none-any.whl size=2656 sha256=65812f146d515777f24df90ef15d91b3749fcfa354b9f9bf50f1a998a96ae028\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/dd/3b/493952a5240d486a83805d65360dedadbadeae71d25e2c877f\n",
            "Successfully built keras.utils\n",
            "Installing collected packages: keras.utils\n",
            "Successfully installed keras.utils-1.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install keras.utils "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e8dawfW380j",
        "outputId": "21e76e75-c316-4931-af59-3b08c25215ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 2., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data[\"sentiment_labels\"].replace({-1: 0}, inplace=True)\n",
        "data['sentiment_labels'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne8X3gXU4NNP",
        "outputId": "ffff727a-2254-4f8c-9743-a5587ce4ae4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32183, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "labels = to_categorical(data['sentiment_labels'], num_classes=3)\n",
        "labels.shape\n",
        "#labels = data['label'].values\n",
        "#labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9YhY7EV4NQe",
        "outputId": "084e7e4f-5585-4fab-97aa-6d18980e6781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13961 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "max_features = 15000 #Max Num Words\n",
        "max_len = 300 #Max Input Length #100\n",
        "token = Tokenizer(num_words=max_features)\n",
        "token.fit_on_texts(data['content'].values)\n",
        "sequences = token.texts_to_sequences(data['content'].values)\n",
        "X = pad_sequences(sequences, maxlen=max_len)#.reshape(-1,1)\n",
        "word_index = token.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOM12eTl4NV6",
        "outputId": "1513ce60-b9c1-418c-d143-92d54e772e9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32183, 3), (32183, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "y = labels#.reshape(-1,1)\n",
        "y.shape,X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps59taH94Wky"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXTVV-XZ4Wob"
      },
      "outputs": [],
      "source": [
        "def build_model(embed_dim=50, optimizer='adam', spatial_dropout=0.3, lstm_dropout=0.25): #lstm_units=128\n",
        "  ls_model = Sequential()\n",
        "  ls_model.add(Embedding(max_features, embed_dim, input_length = X.shape[1]))\n",
        "  #ls_model.add(SpatialDropout1D(spatial_dropout))\n",
        "  ls_model.add((LSTM(embed_dim, dropout=lstm_dropout, recurrent_dropout=lstm_dropout,return_sequences=True)))\n",
        "  ls_model.add(Flatten())\n",
        "  ls_model.add(Dense(3, activation='softmax'))# Dense layers improve overall accuracy and 5–10 units or nodes per layer is a good base.\n",
        "  ls_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
        "  ls_model.summary()\n",
        "  return ls_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZVl1y434Wsk",
        "outputId": "9f0120c6-adc0-4c44-e751-07cb4933d890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "keras_estimator = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "# define the randomized search parameters\n",
        "param_grid = {\n",
        "    'epochs': [5],         # 10, 15],\n",
        "    'embed_dim':[50,100],\n",
        "    'optimizer':['adam','RMSprop'],\n",
        "    'spatial_dropout': [0.2,0.3],\n",
        "    'lstm_dropout': [0.20,0.25],\n",
        "    #'lstm_units': [64,128,256],\n",
        "    'batch_size':[128,64],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpvh--au4lfq",
        "outputId": "fad99db0-0fe9-42c7-eac3-536c62014362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 30000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "101/101 [==============================] - 144s 1s/step - loss: 0.7697 - acc: 0.6733\n",
            "Epoch 2/5\n",
            "101/101 [==============================] - 136s 1s/step - loss: 0.3042 - acc: 0.9046\n",
            "Epoch 3/5\n",
            "101/101 [==============================] - 135s 1s/step - loss: 0.2063 - acc: 0.9325\n",
            "Epoch 4/5\n",
            "101/101 [==============================] - 137s 1s/step - loss: 0.1714 - acc: 0.9443\n",
            "Epoch 5/5\n",
            "101/101 [==============================] - 137s 1s/step - loss: 0.1474 - acc: 0.9555\n",
            "[CV] END batch_size=128, embed_dim=100, epochs=5, lstm_dropout=0.2, optimizer=RMSprop, spatial_dropout=0.3; total time=13.0min\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "101/101 [==============================] - 138s 1s/step - loss: 0.7830 - acc: 0.6754\n",
            "Epoch 2/5\n",
            "101/101 [==============================] - 134s 1s/step - loss: 0.3296 - acc: 0.8945\n",
            "Epoch 3/5\n",
            "101/101 [==============================] - 135s 1s/step - loss: 0.2052 - acc: 0.9326\n",
            "Epoch 4/5\n",
            "101/101 [==============================] - 136s 1s/step - loss: 0.1716 - acc: 0.9438\n",
            "Epoch 5/5\n",
            "101/101 [==============================] - 135s 1s/step - loss: 0.1468 - acc: 0.9524\n",
            "[CV] END batch_size=128, embed_dim=100, epochs=5, lstm_dropout=0.2, optimizer=RMSprop, spatial_dropout=0.3; total time=12.0min\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "101/101 [==============================] - 140s 1s/step - loss: 0.7752 - acc: 0.6586\n",
            "Epoch 2/5\n",
            "101/101 [==============================] - 137s 1s/step - loss: 0.2744 - acc: 0.9156\n",
            "Epoch 3/5\n",
            "101/101 [==============================] - 137s 1s/step - loss: 0.1636 - acc: 0.9483\n",
            "Epoch 4/5\n",
            "101/101 [==============================] - 136s 1s/step - loss: 0.1203 - acc: 0.9661\n",
            "Epoch 5/5\n",
            "101/101 [==============================] - 136s 1s/step - loss: 0.0978 - acc: 0.9718\n",
            "[CV] END batch_size=128, embed_dim=100, epochs=5, lstm_dropout=0.2, optimizer=adam, spatial_dropout=0.3; total time=12.0min\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "101/101 [==============================] - 140s 1s/step - loss: 0.7738 - acc: 0.6580\n",
            "Epoch 2/5\n",
            "101/101 [==============================] - 139s 1s/step - loss: 0.2608 - acc: 0.9191\n",
            "Epoch 3/5\n",
            "101/101 [==============================] - 136s 1s/step - loss: 0.1553 - acc: 0.9512\n",
            "Epoch 4/5\n",
            "101/101 [==============================] - 137s 1s/step - loss: 0.1145 - acc: 0.9646\n",
            "Epoch 5/5\n",
            "101/101 [==============================] - 137s 1s/step - loss: 0.0877 - acc: 0.9737\n",
            "[CV] END batch_size=128, embed_dim=100, epochs=5, lstm_dropout=0.2, optimizer=adam, spatial_dropout=0.3; total time=13.0min\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 300, 50)           750000    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 300, 50)           20200     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 15000)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 45003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 815,203\n",
            "Trainable params: 815,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 98s 471ms/step - loss: 0.6676 - acc: 0.7204\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 95s 471ms/step - loss: 0.2299 - acc: 0.9243\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 96s 478ms/step - loss: 0.1530 - acc: 0.9527\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 99s 488ms/step - loss: 0.1134 - acc: 0.9675\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 96s 474ms/step - loss: 0.0921 - acc: 0.9745\n",
            "[CV] END batch_size=64, embed_dim=50, epochs=5, lstm_dropout=0.2, optimizer=adam, spatial_dropout=0.2; total time= 8.7min\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 300, 50)           750000    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 300, 50)           20200     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 15000)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 45003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 815,203\n",
            "Trainable params: 815,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 100s 481ms/step - loss: 0.6629 - acc: 0.7265\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 96s 473ms/step - loss: 0.2208 - acc: 0.9278\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 96s 477ms/step - loss: 0.1491 - acc: 0.9521\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 94s 468ms/step - loss: 0.1119 - acc: 0.9664\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 95s 469ms/step - loss: 0.0880 - acc: 0.9737\n",
            "[CV] END batch_size=64, embed_dim=50, epochs=5, lstm_dropout=0.2, optimizer=adam, spatial_dropout=0.2; total time= 8.7min\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 184s 897ms/step - loss: 0.5994 - acc: 0.7600\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 181s 897ms/step - loss: 0.2458 - acc: 0.9172\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 179s 888ms/step - loss: 0.2014 - acc: 0.9337\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 179s 885ms/step - loss: 0.1752 - acc: 0.9449\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 178s 880ms/step - loss: 0.1566 - acc: 0.9490\n",
            "[CV] END batch_size=64, embed_dim=100, epochs=5, lstm_dropout=0.25, optimizer=RMSprop, spatial_dropout=0.3; total time=15.6min\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 181s 881ms/step - loss: 0.5753 - acc: 0.7632\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 179s 885ms/step - loss: 0.2297 - acc: 0.9244\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 179s 886ms/step - loss: 0.1898 - acc: 0.9382\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 178s 883ms/step - loss: 0.1662 - acc: 0.9484\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 178s 882ms/step - loss: 0.1451 - acc: 0.9543\n",
            "[CV] END batch_size=64, embed_dim=100, epochs=5, lstm_dropout=0.25, optimizer=RMSprop, spatial_dropout=0.3; total time=16.0min\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 300, 50)           750000    \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 300, 50)           20200     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 15000)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 3)                 45003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 815,203\n",
            "Trainable params: 815,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 98s 470ms/step - loss: 0.6693 - acc: 0.7206\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 95s 472ms/step - loss: 0.2764 - acc: 0.9116\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 95s 470ms/step - loss: 0.2121 - acc: 0.9311\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 95s 468ms/step - loss: 0.1849 - acc: 0.9401\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 95s 470ms/step - loss: 0.1655 - acc: 0.9476\n",
            "[CV] END batch_size=64, embed_dim=50, epochs=5, lstm_dropout=0.2, optimizer=RMSprop, spatial_dropout=0.2; total time= 8.7min\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 300, 50)           750000    \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 300, 50)           20200     \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 15000)             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 45003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 815,203\n",
            "Trainable params: 815,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 97s 468ms/step - loss: 0.6778 - acc: 0.7158\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 95s 468ms/step - loss: 0.2824 - acc: 0.9118\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 94s 465ms/step - loss: 0.2058 - acc: 0.9334\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 95s 472ms/step - loss: 0.1823 - acc: 0.9412\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 95s 470ms/step - loss: 0.1617 - acc: 0.9487\n",
            "[CV] END batch_size=64, embed_dim=50, epochs=5, lstm_dropout=0.2, optimizer=RMSprop, spatial_dropout=0.2; total time= 8.2min\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 184s 894ms/step - loss: 0.5930 - acc: 0.7598\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 182s 899ms/step - loss: 0.2097 - acc: 0.9314\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 181s 895ms/step - loss: 0.1395 - acc: 0.9574\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 182s 901ms/step - loss: 0.1056 - acc: 0.9691\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 182s 901ms/step - loss: 0.0811 - acc: 0.9770\n",
            "[CV] END batch_size=64, embed_dim=100, epochs=5, lstm_dropout=0.25, optimizer=adam, spatial_dropout=0.3; total time=15.7min\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 183s 892ms/step - loss: 0.5643 - acc: 0.7724\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 182s 902ms/step - loss: 0.1957 - acc: 0.9363\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 183s 904ms/step - loss: 0.1334 - acc: 0.9584\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 182s 899ms/step - loss: 0.0985 - acc: 0.9707\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 181s 898ms/step - loss: 0.0761 - acc: 0.9775\n",
            "[CV] END batch_size=64, embed_dim=100, epochs=5, lstm_dropout=0.25, optimizer=adam, spatial_dropout=0.3; total time=16.0min\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "101/101 [==============================] - 140s 1s/step - loss: 0.7985 - acc: 0.6426\n",
            "Epoch 2/5\n",
            "101/101 [==============================] - 139s 1s/step - loss: 0.2780 - acc: 0.9125\n",
            "Epoch 3/5\n",
            "101/101 [==============================] - 139s 1s/step - loss: 0.1645 - acc: 0.9493\n",
            "Epoch 4/5\n",
            "101/101 [==============================] - 141s 1s/step - loss: 0.1216 - acc: 0.9644\n",
            "Epoch 5/5\n",
            "101/101 [==============================] - 139s 1s/step - loss: 0.0975 - acc: 0.9712\n",
            "[CV] END batch_size=128, embed_dim=100, epochs=5, lstm_dropout=0.25, optimizer=adam, spatial_dropout=0.3; total time=13.0min\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "101/101 [==============================] - 144s 1s/step - loss: 0.7600 - acc: 0.6657\n",
            "Epoch 2/5\n",
            "101/101 [==============================] - 139s 1s/step - loss: 0.2599 - acc: 0.9201\n",
            "Epoch 3/5\n",
            "101/101 [==============================] - 139s 1s/step - loss: 0.1578 - acc: 0.9499\n",
            "Epoch 4/5\n",
            "101/101 [==============================] - 140s 1s/step - loss: 0.1173 - acc: 0.9640\n",
            "Epoch 5/5\n",
            "101/101 [==============================] - 140s 1s/step - loss: 0.0934 - acc: 0.9730\n",
            "[CV] END batch_size=128, embed_dim=100, epochs=5, lstm_dropout=0.25, optimizer=adam, spatial_dropout=0.3; total time=13.0min\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 185s 902ms/step - loss: 0.5952 - acc: 0.7574\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 183s 904ms/step - loss: 0.2056 - acc: 0.9347\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 183s 906ms/step - loss: 0.1370 - acc: 0.9587\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 184s 910ms/step - loss: 0.1001 - acc: 0.9694\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 186s 919ms/step - loss: 0.0787 - acc: 0.9765\n",
            "[CV] END batch_size=64, embed_dim=100, epochs=5, lstm_dropout=0.2, optimizer=adam, spatial_dropout=0.2; total time=16.0min\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 300, 100)          1500000   \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              (None, 300, 100)          80400     \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 3)                 90003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,670,403\n",
            "Trainable params: 1,670,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 186s 907ms/step - loss: 0.5824 - acc: 0.7611\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 184s 910ms/step - loss: 0.1971 - acc: 0.9347\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 183s 907ms/step - loss: 0.1311 - acc: 0.9578\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 183s 904ms/step - loss: 0.0936 - acc: 0.9715\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 183s 905ms/step - loss: 0.0760 - acc: 0.9768\n",
            "[CV] END batch_size=64, embed_dim=100, epochs=5, lstm_dropout=0.2, optimizer=adam, spatial_dropout=0.2; total time=16.0min\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, 300, 50)           750000    \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 300, 50)           20200     \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 15000)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 3)                 45003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 815,203\n",
            "Trainable params: 815,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 101s 482ms/step - loss: 0.6702 - acc: 0.7245\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 97s 481ms/step - loss: 0.2379 - acc: 0.9241\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 98s 486ms/step - loss: 0.1626 - acc: 0.9488\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 100s 494ms/step - loss: 0.1233 - acc: 0.9628\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 101s 500ms/step - loss: 0.0977 - acc: 0.9716\n",
            "[CV] END batch_size=64, embed_dim=50, epochs=5, lstm_dropout=0.25, optimizer=adam, spatial_dropout=0.2; total time= 8.6min\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_17 (Embedding)    (None, 300, 50)           750000    \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 300, 50)           20200     \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 15000)             0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 3)                 45003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 815,203\n",
            "Trainable params: 815,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 101s 486ms/step - loss: 0.6619 - acc: 0.7279\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 99s 488ms/step - loss: 0.2218 - acc: 0.9296\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 98s 487ms/step - loss: 0.1540 - acc: 0.9523\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 97s 482ms/step - loss: 0.1126 - acc: 0.9669\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 97s 480ms/step - loss: 0.0879 - acc: 0.9749\n",
            "[CV] END batch_size=64, embed_dim=50, epochs=5, lstm_dropout=0.25, optimizer=adam, spatial_dropout=0.2; total time= 8.7min\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_18 (Embedding)    (None, 300, 50)           750000    \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 300, 50)           20200     \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 15000)             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 3)                 45003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 815,203\n",
            "Trainable params: 815,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "101/101 [==============================] - 72s 684ms/step - loss: 0.8387 - acc: 0.6270\n",
            "Epoch 2/5\n",
            "101/101 [==============================] - 69s 680ms/step - loss: 0.3806 - acc: 0.8652\n",
            "Epoch 3/5\n",
            "101/101 [==============================] - 69s 687ms/step - loss: 0.2018 - acc: 0.9387\n",
            "Epoch 4/5\n",
            "101/101 [==============================] - 68s 675ms/step - loss: 0.1477 - acc: 0.9546\n",
            "Epoch 5/5\n",
            "101/101 [==============================] - 68s 678ms/step - loss: 0.1163 - acc: 0.9659\n",
            "[CV] END batch_size=128, embed_dim=50, epochs=5, lstm_dropout=0.2, optimizer=adam, spatial_dropout=0.3; total time= 6.1min\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_19 (Embedding)    (None, 300, 50)           750000    \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 300, 50)           20200     \n",
            "                                                                 \n",
            " flatten_19 (Flatten)        (None, 15000)             0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 3)                 45003     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 815,203\n",
            "Trainable params: 815,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "101/101 [==============================] - 73s 690ms/step - loss: 0.8204 - acc: 0.6488\n",
            "Epoch 2/5\n",
            "101/101 [==============================] - 69s 685ms/step - loss: 0.3924 - acc: 0.8601\n",
            "Epoch 3/5\n",
            "101/101 [==============================] - 69s 685ms/step - loss: 0.1936 - acc: 0.9391\n",
            "Epoch 4/5\n",
            "101/101 [==============================] - 70s 692ms/step - loss: 0.1435 - acc: 0.9566\n",
            "Epoch 5/5\n",
            "101/101 [==============================] - 69s 686ms/step - loss: 0.1102 - acc: 0.9660\n",
            "[CV] END batch_size=128, embed_dim=50, epochs=5, lstm_dropout=0.2, optimizer=adam, spatial_dropout=0.3; total time= 6.7min\n",
            "Best: 0.919240 using {'spatial_dropout': 0.3, 'optimizer': 'adam', 'lstm_dropout': 0.2, 'epochs': 5, 'embed_dim': 100, 'batch_size': 128}\n",
            "0.918109 (0.004042) with: {'spatial_dropout': 0.3, 'optimizer': 'RMSprop', 'lstm_dropout': 0.2, 'epochs': 5, 'embed_dim': 100, 'batch_size': 128}\n",
            "0.919240 (0.002758) with: {'spatial_dropout': 0.3, 'optimizer': 'adam', 'lstm_dropout': 0.2, 'epochs': 5, 'embed_dim': 100, 'batch_size': 128}\n",
            "0.915821 (0.002518) with: {'spatial_dropout': 0.2, 'optimizer': 'adam', 'lstm_dropout': 0.2, 'epochs': 5, 'embed_dim': 50, 'batch_size': 64}\n",
            "0.918873 (0.001897) with: {'spatial_dropout': 0.3, 'optimizer': 'RMSprop', 'lstm_dropout': 0.25, 'epochs': 5, 'embed_dim': 100, 'batch_size': 64}\n",
            "0.907777 (0.009488) with: {'spatial_dropout': 0.2, 'optimizer': 'RMSprop', 'lstm_dropout': 0.2, 'epochs': 5, 'embed_dim': 50, 'batch_size': 64}\n",
            "0.911853 (0.000267) with: {'spatial_dropout': 0.3, 'optimizer': 'adam', 'lstm_dropout': 0.25, 'epochs': 5, 'embed_dim': 100, 'batch_size': 64}\n",
            "0.916288 (0.002652) with: {'spatial_dropout': 0.3, 'optimizer': 'adam', 'lstm_dropout': 0.25, 'epochs': 5, 'embed_dim': 100, 'batch_size': 128}\n",
            "0.917664 (0.000640) with: {'spatial_dropout': 0.2, 'optimizer': 'adam', 'lstm_dropout': 0.2, 'epochs': 5, 'embed_dim': 100, 'batch_size': 64}\n",
            "0.917798 (0.000171) with: {'spatial_dropout': 0.2, 'optimizer': 'adam', 'lstm_dropout': 0.25, 'epochs': 5, 'embed_dim': 50, 'batch_size': 64}\n",
            "0.916703 (0.004494) with: {'spatial_dropout': 0.3, 'optimizer': 'adam', 'lstm_dropout': 0.2, 'epochs': 5, 'embed_dim': 50, 'batch_size': 128}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "kfold_splits = 2\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "f1 = make_scorer(f1_score, average='weighted')\n",
        "random_search = RandomizedSearchCV(estimator=keras_estimator,  \n",
        "                          #n_jobs=-1, \n",
        "                          verbose=2,\n",
        "                          refit=False,\n",
        "                          scoring=f1,\n",
        "                          cv=kfold_splits,\n",
        "                          error_score='raise',\n",
        "                          return_train_score=True,\n",
        "                          param_distributions=param_grid)\n",
        "\n",
        "tuning_results = random_search.fit(X_train, np.argmax(y_train, axis=1),) \n",
        "\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (tuning_results.best_score_, tuning_results.best_params_))\n",
        "means = tuning_results.cv_results_['mean_test_score']\n",
        "stds = tuning_results.cv_results_['std_test_score']\n",
        "params = tuning_results.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gxvJWMQ74sRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72abc9bb-8cdb-4d35-890b-0fe6bbbba61a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 128,\n",
              " 'embed_dim': 100,\n",
              " 'epochs': 5,\n",
              " 'lstm_dropout': 0.2,\n",
              " 'optimizer': 'adam',\n",
              " 'spatial_dropout': 0.3}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tuning_results.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo8c1aPc4vNT"
      },
      "outputs": [],
      "source": [
        "final_model = build_model(embed_dim=embed_dim, optimizer='adam', spatial_dropout=0.4, lstm_dropout=0.3, lstm_units=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UItNxV0i4wjo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "final_model.fit(X_train, y_train, epochs=35, batch_size=64, class_weight=None,\n",
        "                callbacks= [ModelCheckpoint('model.hdf5', monitor='loss', \n",
        "                                            verbose=1, save_best_only=True)], \n",
        "                verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSvs59kG43LX"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = final_model.evaluate(X_test, y_test)\n",
        "print(\"loss\", loss)\n",
        "print(\"accuracy\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R5tXBKa43OE"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred = ls_model.predict(X_test)\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "y_pred_labels = [labels[x] for x in [np.argmax(x) for x in pred]]\n",
        "y_test_labels = [labels[x] for x in [np.argmax(x) for x in y_test]]\n",
        "confusion = confusion_matrix(y_test_labels, y_pred_labels)\n",
        "confusion_df = pd.DataFrame(confusion,index=[labels], columns=[labels])\n",
        "print(confusion_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JDdLqnb5BIR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PACJnlS843R8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HyperParamTuning_For_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}